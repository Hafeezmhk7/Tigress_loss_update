import data.processed
import modules.quantize

train.iterations=400000
train.learning_rate=0.0005
train.weight_decay=0.01
train.batch_size=64
train.vae_input_dim=768
train.vae_n_layers=3
train.vae_n_cat_feats=0
train.vae_hidden_dims=[512, 256, 128]
train.vae_embed_dim=32
train.vae_codebook_size=256
train.pretrained_rqvae_path=None
train.vae_codebook_normalize=False
train.vae_sim_vq=False
train.save_model_every=80000
train.eval_every=10000
train.log_every=10000
train.dataset=%data.processed.RecDataset.AMAZON
train.commitment_weight=0.25
train.vae_codebook_mode=%modules.quantize.QuantizeForwardMode.ROTATION_TRICK
train.force_dataset_process=False
train.debug=False
train.dataset_folder="dataset/amazon/2023"
train.dataset_split="beauty"
train.log_dir="logdir/rqvae/amazon/2023"
train.wandb_logging=True
train.use_image_features=True # for multi-modal semantic ids
train.feature_combination_mode="cross-attn" # sum or concat if use_image_features
train.use_cross_attn=True
train.run_prefix="2023-cross-attn" # for wandb